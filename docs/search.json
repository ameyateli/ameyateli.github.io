[
  {
    "objectID": "londonmarathon.html",
    "href": "londonmarathon.html",
    "title": "London Marathon",
    "section": "",
    "text": "This data comes from Nicola Rennie’s LondonMarathon R Package containing two data sets scraped from Wikipedia on (1 November 2022) on London Marathon winners, and some general data. Rennie a self proclaimed “enjoyer of endurance races” curated this data set.\nThis data was especially interesting to me as a long distance runner, I hope to one day run a marathon. This data comes from London Marathon data about runners accepted into the race. This is dependent on a few factors: qualifying times (sometimes based on age groups), ballot entry (a lottery entry), running for charity, and many others. Potentially these modes of entry were added as years go by, a reason for the increased accepted runners, or maybe simply marathons have grown in popularity.\nBelow you can see the code and data visualizations of number of accepted runners to the London Marathon from the first year it was established in 1980 to 2020.\n\nlibrary(ggplot2)\nwinners &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-04-25/winners.csv')\nlondon_marathon &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-04-25/london_marathon.csv')\n\nggplot(data = london_marathon, aes(x=Year, y=Accepted)) +\n  geom_point() + labs(title =\"Number of Accepted Runners to the London Marathon vs Year\")\n\n\n\n\n\n\n\n\nThe x-axis shows the years of the London Marathon from 1980 to 2020. The y-axis shows the number of accepted runners for that respective year.\nFrom this graph we can see that there is a general positive correlation between the two variables, with the number of runners generally increasing from year to year. One notable thing about this graph is the year 2020, which had 0 accepted runners. Due to COVID-19, the 40th annual London Marathon was cancelled for mass participation. They still, however, had the elite section (a race for professional runners - like Brigid Kosegei who won the women’s elite section) of the race which is not a part of this data for “accepted runners”.\nBecause this data has a few different variables of interest beyond simply the accepted runners. Below you can select another variable from the data set: Applicants, Starters, and Finishers and plot this against the number of accepted runners to see how these variables interact.\nThis is the shiny application to plot data in comparison to the number of runners accepted to the London Marathon\nAbove is an applet where users can plot the other data as points on the same graph that the accepted runners over the years. This is helpful to see how many people applied for example, or the amount of people who started the race in comparison to the amount of people who were accepted."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ameya Teli",
    "section": "",
    "text": "Welcome! My name is Ameya Teli and I am a student at Pomona College graduating in 2027. I plan on majoring in Mathematics on the statistic track with a minor in Data Science."
  },
  {
    "objectID": "epl.html",
    "href": "epl.html",
    "title": "Premier League 2021-2022",
    "section": "",
    "text": "Analysis of Goals Scored by Home Teams for each month of the English Premier League in 2021-2022.\nThis data comes from Premier League Match Data 2021-2022 via Evan Gower. Gower collected this data from the official website of the Premier League then was cleaned using google sheets.\nMy mom grew up in Manchester, England and her entire family are avid supporters of one of the two teams based in Manchester: Manchester United. Manchester United and many other professional soccer clubs in the United Kingdom play in a league called the English Premier League (often referred to as just the Premier League or the EPL).\nThe EPL has many devoted fans, an American equivalent could be something like the NFL (in terms of their fan base). Many fans may have superstitions such as what they wear, what they’re doing during the game, and many others. However, a large variable that may affect the way that teams play is whether or not they play their game at home. This could be due to having a so-called “home field advantage”, being on the field that they practice on (sometimes), or maybe because there are more fans there supporting them. This second reason may not be a large factor in their performance because of how many fans each EPL team has, often spread throughout the country. However, it is more likely that the fans who support a team live nearby, as the team can be a sort of emblem of the city.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(knitr)\n\nsoccer &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-04-04/soccer21-22.csv')\n\nhead(soccer)\n\n# A tibble: 6 × 22\n  Date       HomeTeam AwayTeam  FTHG  FTAG FTR    HTHG  HTAG HTR   Referee    HS\n  &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 13/08/2021 Brentfo… Arsenal      2     0 H         1     0 H     M Oliv…     8\n2 14/08/2021 Man Uni… Leeds        5     1 H         1     0 H     P Tier…    16\n3 14/08/2021 Burnley  Brighton     1     2 A         1     0 H     D Coote    14\n4 14/08/2021 Chelsea  Crystal…     3     0 H         2     0 H     J Moss     13\n5 14/08/2021 Everton  Southam…     3     1 H         0     1 A     A Madl…    14\n6 14/08/2021 Leicest… Wolves       1     0 H         1     0 H     C Paws…     9\n# ℹ 11 more variables: AS &lt;dbl&gt;, HST &lt;dbl&gt;, AST &lt;dbl&gt;, HF &lt;dbl&gt;, AF &lt;dbl&gt;,\n#   HC &lt;dbl&gt;, AC &lt;dbl&gt;, HY &lt;dbl&gt;, AY &lt;dbl&gt;, HR &lt;dbl&gt;, AR &lt;dbl&gt;\n\n\nBecause the date column in the data set was in day/month/year format and I wanted to group the data in months in a bar chart I created a new data frame called soccer_month which had a new column of month. After converting the date column into a date variable, I extracted the month part of the variable using the function ‘format’.\n\nsoccer_month &lt;- soccer |&gt;\n  mutate(Month = format(as.Date(Date,format=\"%d/%m/%Y\"),\"%m\"))\n\nhead(soccer_month)\n\n# A tibble: 6 × 23\n  Date       HomeTeam AwayTeam  FTHG  FTAG FTR    HTHG  HTAG HTR   Referee    HS\n  &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 13/08/2021 Brentfo… Arsenal      2     0 H         1     0 H     M Oliv…     8\n2 14/08/2021 Man Uni… Leeds        5     1 H         1     0 H     P Tier…    16\n3 14/08/2021 Burnley  Brighton     1     2 A         1     0 H     D Coote    14\n4 14/08/2021 Chelsea  Crystal…     3     0 H         2     0 H     J Moss     13\n5 14/08/2021 Everton  Southam…     3     1 H         0     1 A     A Madl…    14\n6 14/08/2021 Leicest… Wolves       1     0 H         1     0 H     C Paws…     9\n# ℹ 12 more variables: AS &lt;dbl&gt;, HST &lt;dbl&gt;, AST &lt;dbl&gt;, HF &lt;dbl&gt;, AF &lt;dbl&gt;,\n#   HC &lt;dbl&gt;, AC &lt;dbl&gt;, HY &lt;dbl&gt;, AY &lt;dbl&gt;, HR &lt;dbl&gt;, AR &lt;dbl&gt;, Month &lt;chr&gt;\n\n\nThis code converts the number for the month into the month name using the function month.name.\n\nmonths_df &lt;- data.frame(\n  month = c(\"August\", \"September\", \"October\", \"November\", \"December\", \"January\", \"February\", \"March\", \"April\", \"May\"), \n  group = c(1:10))\n\n\nsoccer_grouped &lt;- soccer_month |&gt;\n  group_by(Month) |&gt;\n  summarize(Total_Goals = sum(FTHG), num_games = n()) |&gt;\n  mutate(month_num = c(6,7,8,9,10,1,2,3,4,5)) |&gt; \n  mutate(Month_Name = month.name[as.numeric(Month)]) |&gt;\n  mutate(\n    month_faceted = factor(\n      Month_Name, \n      levels = c(\"August\", \"September\", \"October\", \"November\", \"December\", \"January\", \"February\", \"March\", \"April\", \"May\"))) |&gt;\n  arrange(month_faceted)\n\nThe below data visualization shows the number of goals scored by home teams over the course of the season. It is important to note that the EPL season usually runs from August to May. Hence why the factor variable month_faceted was created and is used on the x-axis.\n\nsoccer_grouped |&gt;\n  ggplot(aes(x=month_faceted, y=Total_Goals)) + \n    geom_bar(stat=\"identity\") +\n    labs(\n      title = \"Goals Scored by Home Teams in the EPL\", \n      x= \"Month\", \n      y = \"Goals by Home Team\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\n\n\n\nThis graph shows that for the 2021-2022 season of the EPL the amount of goals scored by home teams fluctuated. It appears to be the highest in December and at lower levels in September, January, and March. Furthermore, this chart shows a count of goals scored, so if there was a month with less games, it would be expected for there to be less goals because there is less opportunities to score. Also, if there was a significant number of goals for a smaller amount of games it wouldn’t show up as significant on this type of graph.\nThis led me to create a graph that calculates the total goals per game for the home team over the months to compare rather than comparing the total raw sum.\n\nsoccer_grouped &lt;- soccer_grouped |&gt;\n  mutate(goals_per_game = Total_Goals/num_games) \n\n\nsoccer_grouped |&gt;\n  ggplot(\n    aes(\n      x = month_faceted, \n      y = goals_per_game\n      )\n    ) + \n    geom_bar(stat=\"identity\") +\n    labs(\n      title = \"Goals Scored per Game by Home Teams in the EPL\", \n      x= \"Month\", \n      y = \"Goals Scored Per Game\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\n\n\n\nThis chart shows a much more even distribution of goals scored per game in each month unlike the first which had a much greater difference between a few of the months.\nIt would be helpful to add another chart which explores the goals scored by away teams over the course of the season to understand if there is a difference, and if the part of the season impacts the scoring capabilities of each team.\nWe do this below by first doing the same process, this time creating a new data frame called away_grouped.\n\naway_grouped &lt;- soccer_month |&gt;\n  group_by(Month) |&gt;\n  summarize(Total_Goals = sum(FTAG), \n            num_games = n()) |&gt;\n  mutate(month_num = c(6,7,8,9,10,1,2,3,4,5)) |&gt; \n  mutate(Month_Name = month.name[as.numeric(Month)]) |&gt;\n  mutate(\n    month_faceted = factor(\n      Month_Name, \n      levels = c(\"August\", \"September\", \"October\", \"November\", \"December\", \"January\", \"February\", \"March\", \"April\", \"May\"))) |&gt;\n  arrange(month_faceted) |&gt; \n  mutate(goals_per_game = Total_Goals/num_games)\n\nNow we can plot the same graph of goals per month of away teams.\n\naway_grouped |&gt;\n  ggplot(\n    aes(\n      x = month_faceted, \n      y = goals_per_game\n      )\n    ) + \n    geom_bar(stat=\"identity\") +\n    labs(\n      title = \"Goals Scored per Game by Away Teams in the EPL\", \n      x= \"Month\", \n      y = \"Goals Scored Per Game\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\n\n\n\nThis graph shows that there is a bit more variation in terms of goals per game for away teams in comparison of the variation of goals per game for home teams."
  },
  {
    "objectID": "pj2.html",
    "href": "pj2.html",
    "title": "Project",
    "section": "",
    "text": "Link to Database\n\nlibrary(ggplot2)\ntuesdata &lt;- tidytuesdayR::tt_load('2023-12-12')\n\nholiday_movies &lt;- tuesdata$holiday_movies\nholiday_movie_genres &lt;- tuesdata$holiday_movie_genres\n\nholiday_movie_genres\n\n# A tibble: 4,531 × 2\n   tconst    genres   \n   &lt;chr&gt;     &lt;chr&gt;    \n 1 tt0020356 Comedy   \n 2 tt0020823 Drama    \n 3 tt0020823 Romance  \n 4 tt0020985 Comedy   \n 5 tt0020985 Drama    \n 6 tt0021268 Comedy   \n 7 tt0021377 Comedy   \n 8 tt0021377 Romance  \n 9 tt0021381 Adventure\n10 tt0021381 Crime    \n# ℹ 4,521 more rows\n\nholiday_movies\n\n# A tibble: 2,265 × 14\n   tconst   title_type primary_title original_title  year runtime_minutes genres\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;          &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt; \n 1 tt00203… movie      Sailor's Hol… Sailor's Holi…  1929              58 Comedy\n 2 tt00208… movie      The Devil's … The Devil's H…  1930              80 Drama…\n 3 tt00209… movie      Holiday       Holiday         1930              91 Comed…\n 4 tt00212… movie      Holiday of S… Prazdnik svya…  1930              83 Comedy\n 5 tt00213… movie      Sin Takes a … Sin Takes a H…  1930              81 Comed…\n 6 tt00213… movie      Sinners' Hol… Sinners' Holi…  1930              60 Adven…\n 7 tt00230… movie      Husband's Ho… Husband's Hol…  1931              70 Drama \n 8 tt00248… movie      Beggar's Hol… Beggar's Holi…  1934              60 Crime…\n 9 tt00250… movie      Cowboy Holid… Cowboy Holiday  1934              56 Weste…\n10 tt00250… movie      Death Takes … Death Takes a…  1934              79 Drama…\n# ℹ 2,255 more rows\n# ℹ 7 more variables: simple_title &lt;chr&gt;, average_rating &lt;dbl&gt;,\n#   num_votes &lt;dbl&gt;, christmas &lt;lgl&gt;, hanukkah &lt;lgl&gt;, kwanzaa &lt;lgl&gt;,\n#   holiday &lt;lgl&gt;\n\n\nFirst Plot - What genre do movies with love in the title fall under?\n\nlibrary(stringr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\ncolnames(holiday_movies)\n\n [1] \"tconst\"          \"title_type\"      \"primary_title\"   \"original_title\" \n [5] \"year\"            \"runtime_minutes\" \"genres\"          \"simple_title\"   \n [9] \"average_rating\"  \"num_votes\"       \"christmas\"       \"hanukkah\"       \n[13] \"kwanzaa\"         \"holiday\"        \n\n#holiday_movies$simple_title\n\nlove &lt;- holiday_movies|&gt;\n  filter(str_detect(simple_title, \"love\"))\nlove\n\n# A tibble: 32 × 14\n   tconst   title_type primary_title original_title  year runtime_minutes genres\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;          &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt; \n 1 tt00528… movie      Holiday for … Holiday for L…  1959             103 Comedy\n 2 tt00855… tvMovie    The Gift of … The Gift of L…  1983              96 Drama \n 3 tt00999… tvMovie    The Kid Who … The Kid Who L…  1990             118 Drama \n 4 tt01370… tvMovie    A Holiday fo… Christmas in …  1996             105 Drama…\n 5 tt04142… tvMovie    Love Hina Ch… Rabu Hina kur…  2000              46 Anima…\n 6 tt04185… movie      Christmas in… Christmas in …  2004             118 Comed…\n 7 tt10623… tvMovie    Christmas Lo… Christmas Lov…  2019              86 Comed…\n 8 tt11171… tvMovie    Our Christma… Our Christmas…  2019              82 Drama…\n 9 tt11666… tvMovie    Inn Love by … Inn for Chris…  2020              88 Comed…\n10 tt12418… movie      A Christmas … A Christmas T…  2020              70 Roman…\n# ℹ 22 more rows\n# ℹ 7 more variables: simple_title &lt;chr&gt;, average_rating &lt;dbl&gt;,\n#   num_votes &lt;dbl&gt;, christmas &lt;lgl&gt;, hanukkah &lt;lgl&gt;, kwanzaa &lt;lgl&gt;,\n#   holiday &lt;lgl&gt;\n\nlove_genre &lt;- love|&gt;\n  mutate(genre_list = genres)|&gt;\n  separate(genres, c('first','second', 'third'))\nlove_genre\n\n# A tibble: 32 × 17\n   tconst    title_type primary_title original_title  year runtime_minutes first\n   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;          &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt;\n 1 tt0052897 movie      Holiday for … Holiday for L…  1959             103 Come…\n 2 tt0085593 tvMovie    The Gift of … The Gift of L…  1983              96 Drama\n 3 tt0099930 tvMovie    The Kid Who … The Kid Who L…  1990             118 Drama\n 4 tt0137000 tvMovie    A Holiday fo… Christmas in …  1996             105 Drama\n 5 tt0414243 tvMovie    Love Hina Ch… Rabu Hina kur…  2000              46 Anim…\n 6 tt0418599 movie      Christmas in… Christmas in …  2004             118 Come…\n 7 tt106234… tvMovie    Christmas Lo… Christmas Lov…  2019              86 Come…\n 8 tt111713… tvMovie    Our Christma… Our Christmas…  2019              82 Drama\n 9 tt116669… tvMovie    Inn Love by … Inn for Chris…  2020              88 Come…\n10 tt124182… movie      A Christmas … A Christmas T…  2020              70 Roma…\n# ℹ 22 more rows\n# ℹ 10 more variables: second &lt;chr&gt;, third &lt;chr&gt;, simple_title &lt;chr&gt;,\n#   average_rating &lt;dbl&gt;, num_votes &lt;dbl&gt;, christmas &lt;lgl&gt;, hanukkah &lt;lgl&gt;,\n#   kwanzaa &lt;lgl&gt;, holiday &lt;lgl&gt;, genre_list &lt;chr&gt;\n\nlove_movies &lt;- inner_join(love_genre, holiday_movie_genres, by = \"tconst\")\nlove_movies\n\n# A tibble: 66 × 18\n   tconst    title_type primary_title original_title  year runtime_minutes first\n   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;          &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt;\n 1 tt0052897 movie      Holiday for … Holiday for L…  1959             103 Come…\n 2 tt0085593 tvMovie    The Gift of … The Gift of L…  1983              96 Drama\n 3 tt0099930 tvMovie    The Kid Who … The Kid Who L…  1990             118 Drama\n 4 tt0137000 tvMovie    A Holiday fo… Christmas in …  1996             105 Drama\n 5 tt0137000 tvMovie    A Holiday fo… Christmas in …  1996             105 Drama\n 6 tt0137000 tvMovie    A Holiday fo… Christmas in …  1996             105 Drama\n 7 tt0414243 tvMovie    Love Hina Ch… Rabu Hina kur…  2000              46 Anim…\n 8 tt0414243 tvMovie    Love Hina Ch… Rabu Hina kur…  2000              46 Anim…\n 9 tt0414243 tvMovie    Love Hina Ch… Rabu Hina kur…  2000              46 Anim…\n10 tt0418599 movie      Christmas in… Christmas in …  2004             118 Come…\n# ℹ 56 more rows\n# ℹ 11 more variables: second &lt;chr&gt;, third &lt;chr&gt;, simple_title &lt;chr&gt;,\n#   average_rating &lt;dbl&gt;, num_votes &lt;dbl&gt;, christmas &lt;lgl&gt;, hanukkah &lt;lgl&gt;,\n#   kwanzaa &lt;lgl&gt;, holiday &lt;lgl&gt;, genre_list &lt;chr&gt;, genres &lt;chr&gt;\n\nggplot(love_movies, aes(x = genres))+ geom_bar(stat = \"count\")+labs(title = \"Genres of Holiday Movies with Love in the Title\", x = \"Genre\")\n\n\n\n\n\n\n\n\nThis plot shows that the most prevalent genre’s for holiday movies about love are Romance, Family, Drama, and Comedy.\n2nd Plot - Genres of Holiday Movies\n\nggplot(holiday_movie_genres, aes(x = genres)) + \n  geom_bar(stat = \"count\") + \n  labs(title = \"Genres of Holiday Movies\", x = \"Genre\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n3rd Plot -"
  },
  {
    "objectID": "shake.html",
    "href": "shake.html",
    "title": "Shakespeare Textual Analysis",
    "section": "",
    "text": "This my textual analysis of Shakespeare dialogue in his tragedy “Romeo and Juliet”.\nThis data was curated by Nicola Rennie from The Complete Works of William Shakespeare the Web’s first edition of the Complete Works of William Shakespeare.\n\nhamlet &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/hamlet.csv')\nmacbeth &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/macbeth.csv')\nromeo_juliet &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/romeo_juliet.csv')\n\n\nHow much is death mentioned in Romeo and Juliet?\nTo find a bar plot that explains which character mentions the most I filtered through the dialogue and kept only the pieces of dialogue which contained the word “death”.\n\nlibrary(stringr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\ndeathrj &lt;- romeo_juliet |&gt;\n filter(str_detect(dialogue, \"death\")) \n  \n\nggplot(deathrj, aes(x = character)) +\n  geom_bar(stat = \"count\") + \n  labs(title = \"Which character mentions death the most?\", x = \"Character\") + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\nThis first graph shows that Romeo has the most instances of the word “death” in his dialogue and Friar Laurence had the second most in his dialogue. This is interesting because it makes sense that Romeo says death the most as he eventually is one of those who die in this tragedy and Friar Laurence is the one to encourage this from selling a sleeping potion. As Romeo has more dialogue presumably as one of the more main characters it makes sense that he has more mentions by count versus the Apothecary who sells Romeo poison that will kill him.\nThis next bar plot will look at which act has the most mentions of death using the data frame we created called deathrj for the first graph.\n\nact_num &lt;- deathrj |&gt;\n  mutate(act = str_extract(act, \"(?&lt;=\\\\s)\\\\S+\"))  \n  \nggplot(act_num, aes(x = act)) + \n  geom_bar(stat = \"count\") + \n  labs(title = \"Which act has most mentions of death?\", x = \"Act\") \n\n\n\n\n\n\n\n\nRomeo and Juliet die in Act 5 Scene 3, so having the most mentions of death in Act 3 is interesting. Maybe there is some foreshadowing happening here or something else significant which we can look through in the next plot.\n\n\nPunctuation\nThis plot will analyze specifically dialogue in Act 3 looking for exclamations and question marks which indicate a strong emotion in the dialogue.\n\nfiltered_act_num &lt;- act_num |&gt;\n  filter(act == \"III\")|&gt;\n  mutate(strong_punctuation = str_detect(dialogue, \"!+|\\\\?+\")) |&gt;\n  mutate(scene = str_extract(scene, \"(?&lt;=\\\\s)\\\\S+\"))  \n  \n\nggplot(filtered_act_num, aes(x = scene, fill = strong_punctuation))+\n  geom_bar(position = \"fill\") + \n  labs(title = \"Proportion of strong punctuation marks across scenes\", x = \"Scene\", y = \"Proportion\")\n\n\n\n\n\n\n\n\nThis shows that there is a greater proportion of strong punctuation in Scene 5 than the rest. So potentially the strongest emotions in relation to death occur here. We will also check which scene had the most mentions of death below.\n\nggplot(filtered_act_num, aes(x = scene)) +\n  geom_bar(stat = \"count\") + \n  labs(title = \"Mentions of death across scenes in Act III\", x = \"Scene\", y = \"Count\")\n\n\n\n\n\n\n\n\nThis may indicate that the mentions of death in the other scenes are less emotional and thus use less strong punctuation. We will look for the following word, symbol, or space after death, to see how they compare.\n\nfiltered_act_num &lt;- act_num |&gt;\n  filter(act == \"III\")|&gt;\n  mutate(word_after_death = str_extract(dialogue, \"death\\\\s*\\\\S+\"))\n\nggplot(filtered_act_num, aes(x = word_after_death))+\n  geom_bar(stat = \"count\")+\n  labs(title = \"Death and the Word/Character after in Act III\", \n       x = \"Death + Word\", \n       y = \"Count\")+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe most common thing following death is a comma, indicating that death ends a thought of most of the dialogue in Act III. However, not a complete thought as a period would indicate. This is interesting if we wanted to analyze the style that Shakespeare uses to foreshadow the impending doom of Romeo and Juliet and those others who face tragic endings.\n\nhead(filtered_act_num)\n\n# A tibble: 6 × 6\n  act   scene    character dialogue                 line_number word_after_death\n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt; &lt;chr&gt;           \n1 III   Scene I  Mercutio  cat, to scratch a man t…        1525 death!          \n2 III   Scene I  Benvolio  Stand not amazed: the p…        1560 death,          \n3 III   Scene I  Benvolio  Cold death aside, and w…        1590 death aside,    \n4 III   Scene II Juliet    Than the death-darting …        1676 death-darting   \n5 III   Scene II Juliet    Some word there was, wo…        1739 death,          \n6 III   Scene II Juliet    Hath slain ten thousand…        1745 &lt;NA&gt;            \n\n\nUpon viewing the first few lines of this data frame we can see that “Tybalt’s death” is mentioned a great amount, so perhaps the reason death is mentioned so much in this Act is because this character actually did die.\n\n\nRivaling Families\nAnother important factor on the play is the two rivaling families, the Montague’s and the Capulet’s. The entire basis of the play is that Romeo is in love with Juliet but because they are each from the opposing family their love is forbidden. This ultimately leads to the deaths and tragedy that ensues in the play.\nHere is further analysis on how family names associate with mentions of death:\nThese next two plots analyze which characters mention the Montague’s and the Capulet’s the most.\n\nmontague &lt;- romeo_juliet |&gt;\n  mutate(dialogue_lower = str_to_lower(dialogue))|&gt;\n  filter(str_detect(dialogue_lower, \"montague\")) |&gt;\n  filter(character != \"[stage direction]\") |&gt;\n  mutate(Family = \"Montague\") #this is useful for the next plot \n\nmontague |&gt;\n  ggplot(aes(x = character)) +\n  geom_bar(stat = \"count\") + \n  labs(title = \"Which character mentions the Montague family the most?\", x = \"Character\") + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\ncapulet &lt;- romeo_juliet |&gt;\n  mutate(dialogue_lower = str_to_lower(dialogue))|&gt;\n  filter(str_detect(dialogue_lower, \"capulet\")) |&gt;\n  filter(character != \"[stage direction]\") |&gt;\n  mutate(Family = \"Capulet\")\n\ncapulet |&gt;\n  ggplot(aes(x = character)) +\n  geom_bar(stat = \"count\") + \n  labs(title = \"Which character mentions the Capulet family the most?\", x = \"Character\") + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\nThese two plots show that Juliet mentions the Montague family the most and Benvolio, Prince, and Romeo mention the Capulet family the most. This is interesting because Romeo and Juliet have the most dialogue presumably as they are main characters so they mention the family names the most.\nThe previous code assigned “Montague” to the dialogue which includes the Montagues and “Capulet” to the dialogue including the Capulets. In this next plot I will create a bar plot of the number of mentions of each family in each scene. Then see if this is related to the previous plots that counted the prevalence of the word deaths.\n\nlibrary(dplyr)\n\n#binding both the data frames together to be able to create a bar plot with the bars next to each other for each act \n\nmontague_and_capulet &lt;- bind_rows(montague, capulet)\n\nmontague_and_capulet_summary &lt;- montague_and_capulet |&gt;\n  group_by(act, Family) |&gt;\n  summarize(frequency = n())\n  \n\nmontague_and_capulet_summary |&gt;\n  ggplot(aes(x = act, y = frequency, fill = Family)) + \n  geom_bar(stat = \"identity\", position = position_dodge())\n\n\n\n\n\n\n\n\nLooking back to the acts which have the most mentions of death there is not a clear correlation between these two graphs. Act III has the most mentions of death whereas this graph shows that Act I has the most prevalence of family name mentions. This could be because of the first act being the place where characters and families are established so this may not be especially telling, or conversely it could be foreshadowing for the future tragedies which are coming."
  },
  {
    "objectID": "simstudy.html",
    "href": "simstudy.html",
    "title": "Permutation Test",
    "section": "",
    "text": "Source: Rosen B and Jerdee T. 1974. Influence of sex role stereotypes on personnel decisions. Journal of Applied Psychology 59(1):9-14.\nObjective: See if there is a correlation between gender and being promoted from a study in the 1970s about bank manager recommendations based on sex. We want to show that the proportion of women who are promoted is less than men and that this is significant.\nOur null hypothesis is that gender does not affect the likelihood that men or women are promoted.\n\nThe Data\nThis data includes 48 observations with two variables: sex (a factor with levels female and male) and decision (a factor with levels not promoted and promoted)\n\nlibrary(openintro)\nlibrary(ggplot2)\n\n\nhead(sex_discrimination)\n\n# A tibble: 6 × 2\n  sex   decision\n  &lt;fct&gt; &lt;fct&gt;   \n1 male  promoted\n2 male  promoted\n3 male  promoted\n4 male  promoted\n5 male  promoted\n6 male  promoted\n\n\n\n\nSummary Statistics\nThe following code is to calculate the summary statistics for our data.\n\nlibrary(dplyr)\n\nsex_summary &lt;- sex_discrimination |&gt; \n  group_by(sex) |&gt;\n  summarize(prop_promoted = mean(decision == \"promoted\")) \nsex_summary\n\n# A tibble: 2 × 2\n  sex    prop_promoted\n  &lt;fct&gt;          &lt;dbl&gt;\n1 male           0.875\n2 female         0.583\n\nsex_diff &lt;- sex_summary |&gt;\n  summarize(prop_diff = diff(prop_promoted))\nsex_diff\n\n# A tibble: 1 × 1\n  prop_diff\n      &lt;dbl&gt;\n1    -0.292\n\n\nThis tells us that the proportion of men promoted from the data is 0.875 whereas the proportion of women promoted from the data is approximately 0.583. Also we can see that the difference in proportion between the women who were promoted and the men who were promoted is -0.2916667.\n\n\nNull Sampling Distribution\nNow we want to generate a null-sampling distribution by permuting the decision, assigning a random decision for every person from the 35 promoted and 13 not promoted individuals.\n\nlibrary(dplyr)\nlibrary(purrr)\n\nset.seed(4747)\n\nperm_data &lt;- function(rep, data){\n data |&gt; \n    mutate(decision_perm = sample(decision, replace = FALSE)) |&gt;\n    group_by(sex) |&gt;\n    summarize(perm_prop_promoted = mean(decision_perm == \"promoted\")) |&gt;\n    summarize(perm_prop_diff = diff(perm_prop_promoted), rep = rep)\n}\n\n#map the function perm_data to create many \nperm_stats &lt;- map(1:5000, perm_data, data = sex_discrimination) |&gt;\n  list_rbind()\n\n\nVisualization\n\nperm_stats |&gt;\n  ggplot(aes(x = perm_prop_diff)) + \n  geom_histogram(binwidth = 0.05) + \n  geom_vline(aes(xintercept = -0.2916667), color = \"red\") +\n  labs(title = \"Null Distribution of Promotion Differences by Gender\", \n       x = \"Proportion Difference (Permuted Data)\",\n       y = \"Frequency\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\nThis is a graph of the null sampling distribution, that is we permuted the data many times assigning the existing decision labels randomly (shuffling) for men and women. Then plotted this on the above histogram. The red vertical line shows our observed difference from the initial the sex_discrimination data from the study.\n\nsum(perm_stats&lt;= -0.2916667 )\n\n[1] 18\n\n\nThere are only 18 entries from our null sampling distribution that are greater than or equal to our observed difference from the sampling distribution. This gives us a p value of 0.036 which is very small. Small enough for us to reject our null hypothesis. Thus the gender of the person does make a difference on whether or not they were promoted. More specifically to the point of this simulation study, the proportion of females promoted was significantly fewer than the proportion of men who were promoted.\n\n\n\nSignificance\nThis data can be generalized to the promotions of bank managers in the 1970s. We can see that during this time period, gender played a significant role in promotion decisions, as women were promoted in much lower rates than men. This data is specific to the context of bank manager recommendations and the time frame, so we cannot generalize to now. To do so we would need further data that is more recent."
  },
  {
    "objectID": "project4.html",
    "href": "project4.html",
    "title": "ameyateli.github.io",
    "section": "",
    "text": "library(dplyr)\nlibrary(dbplyr)\n\n\nlibrary(RMariaDB)\nlibrary(DBI)\ncon_wai &lt;- dbConnect(\n  MariaDB(), \n  host = \"scidb.smith.edu\",\n  user = \"waiuser\", \n  password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\n\nSHOW TABLES;\n\n\n7 records\n\n\nTables_in_wai\n\n\n\n\nCodebook\n\n\nMeasurements\n\n\nMeasurements_pre2020\n\n\nPI_Info\n\n\nPI_Info_OLD\n\n\nSubjects\n\n\nSubjects_pre2020\n\n\n\n\n\n\nDESCRIBE Measurements;\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSession\nint\nNO\nPRI\nNA\n\n\n\nEar\nvarchar(50)\nNO\nPRI\n\n\n\n\nInstrument\nvarchar(50)\nNO\nPRI\n\n\n\n\nAge\nfloat\nYES\n\nNA\n\n\n\nAgeCategory\nvarchar(50)\nYES\n\nNA\n\n\n\nEarStatus\nvarchar(50)\nYES\n\nNA\n\n\n\nTPP\nfloat\nYES\n\nNA\n\n\n\nAreaCanal\nfloat\nYES\n\nNA\n\n\n\n\n\n\n\nSELECT *\nFROM Measurements\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSession\nEar\nInstrument\nAge\nAgeCategory\nEarStatus\nTPP\nAreaCanal\nPressureCanal\nSweepDirection\nFrequency\nAbsorbance\nZmag\nZang\n\n\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n210.938\n0.0333379\n113780000\n-0.233504\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n234.375\n0.0315705\n103585000\n-0.235778\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n257.812\n0.0405751\n92951696\n-0.233482\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n281.250\n0.0438399\n86058000\n-0.233421\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n304.688\n0.0486400\n79492800\n-0.232931"
  },
  {
    "objectID": "sqlproject.html",
    "href": "sqlproject.html",
    "title": "SQL Project",
    "section": "",
    "text": "Source: This data comes from the WAI-Database hosted by Smith College (https://www.science.smith.edu/wai-database/home/about/) doi.org/10.35482/egr.001.2022\nThe figure comes from Susan E. Voss Ear Hear. 2019 Nov-Dec;40(6):1481. doi: 10.1097/AUD.0000000000000790\nThe goal of this project is to: (1) Recreate Figure 1 from Voss (2020) which comes from Ear and Hearing by Susan E. Voss and the Smith College Picker Engineering Program (2) Create my own graph that groups by a demographic variable in a particular study rather than all absorbances by study (for this project I will use sex)\n\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\nlibrary(RMariaDB)\nlibrary(DBI)\ncon_wai &lt;- dbConnect(\n  MariaDB(), \n  host = \"scidb.smith.edu\",\n  user = \"waiuser\", \n  password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\nBelow is the first 5 rows of the measurements table.\n\nSELECT *\nFROM Measurements\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSession\nEar\nInstrument\nAge\nAgeCategory\nEarStatus\nTPP\nAreaCanal\nPressureCanal\nSweepDirection\nFrequency\nAbsorbance\nZmag\nZang\n\n\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n210.938\n0.0333379\n113780000\n-0.233504\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n234.375\n0.0315705\n103585000\n-0.235778\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n257.812\n0.0405751\n92951696\n-0.233482\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n281.250\n0.0438399\n86058000\n-0.233421\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n304.688\n0.0486400\n79492800\n-0.232931\n\n\n\n\n\nThis data shows that each study recorded absorbance of each subject many many times, that is of each ear many times and with many different frequencies.\nTo recreate Figure 1 from Voss (2020) we must find the mean absorbance for each ear in each study, then plot it against the frequency. So I have to group the data by the study and frequency.\n\nSELECT \n  Measurements.Identifier, \n  Frequency, \n  AVG(Absorbance) AS Mean_Absorbance, \n  CONCAT(AuthorsShortList, \" (\", Year, \") \", \"N=\", COUNT(DISTINCT SubjectNumber, Ear), \" ; \", Instrument) AS Label\nFROM Measurements \nJOIN PI_Info ON Measurements.Identifier = PI_Info.Identifier\nWHERE Measurements.Identifier IN (\n\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\", \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\"\n) \nAND Frequency BETWEEN 200 AND 8000\nGROUP BY Measurements.Identifier, Frequency, Instrument\n\nThis table, table_one, has the information to add to the legend such as the author list, year, instrument, and is saved as Label.\nThis code creates a data frame with the information we need for the legend, including the Authors, the year, and the instrument used in the study from PI_Info. Then it is joined with Measurements using JOIN because to have the information from the study as well as the information we need for the legend.\nHere I create a new data frame from joining table_one and legend to add the data from legend that we was not present in our initial filtering of table_one. Furthermore, the graph by Voss, instead of having entries with “other” for the Instrument it has “not commercial system”, so I replaced those. The last mutate is to create the legend entries like that of the original graph.\nHere I create the graph using ggplot using color = name to make each name have a different associated color rather than study allowing it to be in the legend.\n\ntable_one |&gt;\n  ggplot(aes(\n      x = Frequency, \n      y = Mean_Absorbance, \n      color = Label)) + \n  geom_line(size = 0.5) +\n  theme_bw() + \n  theme(\n    legend.position = c(0.2, 0.8),\n    legend.key.size = unit(0.05, 'cm'), \n    axis.text.x = element_text(size = 6), \n    legend.title = element_blank(), \n    legend,text = element_text(size = 7),\n    panel.grid.major = element_line(color = \"grey90\"), \n    panel.grid.minor = element_line(color = \"grey95\"), \n    plot.title = element_text(size = 14, face = \"bold\"), \n    plot.margin = margin(20,20,20,20), \n    plot.background = element_rect(fill = \"grey90\", color = NA),\n    panel.background = element_rect(fill = \"white\", color = NA)\n  ) + \n  labs(\n    x = \"Frequency (Hz)\", \n    y = \"Mean Absorbance\", \n    title = \"Mean absorbance from each publication in WAI database\") + \n  ylim(0,1) +\n  scale_x_log10(\n    limits = c(200, 8000),\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000)\n  )  \n\n\n\n\n\n\n\n\nThis graph is meant to be a recreation of the one by Voss. It shows that as frequency increases and is around 3000 Hz, the mean absorbance of most participants was at its peak. So from the participants in these studies, the best absorption their ears were able to do was at this frequency. Also very quickly after this there is a steep drop in the graph, which may indicate that after this ideal frequency of 3000 Hz it is harder for ears to absorb.\n\nPart 2\nSource: Non-invasive estimation of middle-ear input impedance and efficiency by Lewis JD and Neely ST (2015) J Acoust Soc Am. 2015 Aug 19;138(2):977–993. doi: 10.1121/1.4927408\nPart 2 of this project explores specifically the study done by Lewis and Neely in 2015. In their study they track sex as a variable. The goal of this section is to create a graph like the one above, but instead of having a line for each study, have a line for each gender in this specific study.\nBelow is the first 10 rows of the Subjects table of Lewis and Neely’s study.\n\nSELECT * \nFROM Subjects\nWHERE Identifier = \"Lewis_2015\"\nLIMIT 0, 10\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSessionTotal\nAgeFirstMeasurement\nAgeCategoryFirstMeasurement\nSex\nRace\nEthnicity\nLeftEarStatusFirstMeasurement\nRightEarStatusFirstMeasurement\nSubjectNotes\n\n\n\n\nLewis_2015\n1\n2\n25\nAdult\nFemale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):2.8989e-05 m^2, shallow placement(session2):4.1712e-05 m^2; Left ear data NA\n\n\nLewis_2015\n2\n2\n22\nAdult\nFemale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):3.1677e-05 m^2, shallow placement(session2):4.1669e-05 m^2; Left ear data NA\n\n\nLewis_2015\n3\n2\n37\nAdult\nFemale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):2.2295e-05 m^2, shallow placement(session2):2.9556e-05 m^2; Left ear data NA\n\n\nLewis_2015\n4\n2\n21\nAdult\nMale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):2.6597e-05 m^2, shallow placement(session2):3.3578e-05 m^2; Left ear data NA\n\n\nLewis_2015\n5\n2\n25\nAdult\nFemale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):3.6921e-05 m^2, shallow placement(session2):4.7702e-05 m^2; Left ear data NA\n\n\nLewis_2015\n6\n2\n45\nAdult\nMale\nBlack\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):3.1565e-05 m^2, shallow placement(session2):3.2389e-05 m^2; Left ear data NA;Subject identified as black or african american\n\n\nLewis_2015\n7\n2\n33\nAdult\nMale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):2.2472e-05 m^2, shallow placement(session2):2.8156e-05 m^2; Left ear data NA\n\n\nLewis_2015\n8\n2\n26\nAdult\nFemale\nAsian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):3.3991e-05 m^2, shallow placement(session2):3.7724e-05 m^2; Left ear data NA;Subject did not differentiate between Chinese and Asian\n\n\nLewis_2015\n9\n2\n25\nAdult\nFemale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):3.2203e-05 m^2, shallow placement(session2):3.9391e-05 m^2; Left ear data NA\n\n\nLewis_2015\n10\n2\n27\nAdult\nFemale\nCaucasian\nNonHispanic\nNormal\nNormal\nRight ear: deep probe placement(session1):1.8787e-05 m^2, shallow placement(session2):3.0184e-05 m^2; Left ear data NA\n\n\n\n\n\nTo create this visualization I first create a new data frame table_two which is all the frequencies and mean absorbances for the Lewis_2015 study joined with Measurements to obtain the Mean_Absorbance for each frequency as observed in part 1, however, this section adds the additional group of “Sex”.\n\nSELECT \n  Measurements.Identifier, \n  Frequency, \n  AVG(Absorbance) AS Mean_Absorbance, \n  Sex, \n  AuthorsShortList\nFROM Measurements \nJOIN PI_Info ON Measurements.Identifier = PI_Info.Identifier\nJOIN Subjects ON Subjects.SubjectNumber = Measurements.SubjectNumber \nWHERE Measurements.Identifier = \"Lewis_2015\" \nAND Absorbance &gt;= 0\nAND Frequency BETWEEN 200 AND 8000\nGROUP BY Sex, Identifier, Frequency\n\nUsing this data frame I can use ggplot to plot the data.\n\ntable_two |&gt;\nggplot(\n  aes(\n    x = Frequency, \n    y = Mean_Absorbance, \n    color = Sex)) + \n  geom_line() + \n  labs(title = \"Mean Absorbance vs. Frequency based on gender in Lewis and Neely's 2015 study\", y = \"Mean Absorbance\", x = \"Frequency (Hz)\") + \n  scale_x_log10(limits = c(200, 8000),\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000)) +\n  ylim(0,1) + \n  theme_bw() + \n  theme(\n    legend.position = c(0.1, 0.8),\n    legend.key.size = unit(0.05, 'cm'), \n    axis.text.x = element_text(size = 6), \n    legend.title = element_blank(), \n    legend,text = element_text(size = 10),\n    panel.grid.major = element_line(color = \"grey90\"), \n    panel.grid.minor = element_line(color = \"grey95\"), \n    plot.title = element_text(size = 14, face = \"bold\"), \n    plot.margin = margin(20,20,20,20), \n    plot.background = element_rect(fill = \"grey90\", color = NA),\n    panel.background = element_rect(fill = \"white\", color = NA)\n  )\n\n\n\n\n\n\n\n\nThis graph has three different colored lines. One for female, male and unknown (possibly all the participants whose genders were not recorded). This graph shows that all three of the sexes have similar Mean Absorbances at frequencies. However, it appears that the unknown gender has much more fluctuations than the other two. This could be due to the mixture of genders that are in this group, or that it may be larger than the others. Zooming into the female and male lines, we can see that the male line is generally above the female line from 1000 Hz to 6000 Hz. However, at most other points the lines are almost identical."
  },
  {
    "objectID": "slideshow.html#project-1-data-visualizations",
    "href": "slideshow.html#project-1-data-visualizations",
    "title": "Overview of DS002 Projects",
    "section": "Project 1: Data Visualizations",
    "text": "Project 1: Data Visualizations\nFor this project one of the data sets I worked with was about the London Marathon from 1980 to 2020.\n\nLondon Marathon: contains data about applicants, accepted runners, starters, finishers, and data on winners in the elite section\n\n\nhead(london_marathon)\n\n# A tibble: 6 × 8\n  Date        Year Applicants Accepted Starters Finishers Raised\n  &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 1981-03-29  1981      20000     7747     7055      6255     NA\n2 1982-05-09  1982      90000    18059    16350     15116     NA\n3 1983-04-17  1983      60000    19735    16500     15793     NA\n4 1984-05-13  1984      70000    21142    16992     15675     NA\n5 1985-04-21  1985      83000    22274    17500     15873     NA\n6 1986-04-20  1986      80000    25566    19261     18067     NA\n# ℹ 1 more variable: `Official charity` &lt;chr&gt;"
  },
  {
    "objectID": "slideshow.html#graph",
    "href": "slideshow.html#graph",
    "title": "Overview of Projects",
    "section": "Graph",
    "text": "Graph"
  },
  {
    "objectID": "slideshow.html#visualizations",
    "href": "slideshow.html#visualizations",
    "title": "Overview of Projects",
    "section": "Visualizations",
    "text": "Visualizations"
  },
  {
    "objectID": "slideshow.html#london-marathon",
    "href": "slideshow.html#london-marathon",
    "title": "Overview of DS002 Projects",
    "section": "London Marathon",
    "text": "London Marathon\n\nThis is the shiny application to plot data in comparison to the number of runners accepted to the London Marathon"
  },
  {
    "objectID": "slideshow.html#epl",
    "href": "slideshow.html#epl",
    "title": "Overview of Projects",
    "section": "EPL",
    "text": "EPL"
  },
  {
    "objectID": "slideshow.html#project-2-shakespeare-textual-analysis",
    "href": "slideshow.html#project-2-shakespeare-textual-analysis",
    "title": "Overview of DS002 Projects",
    "section": "Project 2: Shakespeare Textual Analysis",
    "text": "Project 2: Shakespeare Textual Analysis"
  }
]